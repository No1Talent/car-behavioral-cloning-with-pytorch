{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "#from torchnet.meter import AverageValueMeter\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_dir': './selfdrivingcar-data/lap1/',\n",
    "    'nb_epoch': 50,\n",
    "    'test_size': 64,\n",
    "    'learning_rate': 0.0002,\n",
    "    'keep_prob': 136,\n",
    "    'samples_per_epoch': 64,\n",
    "    'batch_size': 100,\n",
    "    'save_best_only': 64,\n",
    "    'cuda': True,\n",
    "    'seed': 7\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \"\"\"\n",
    "    #reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(os.getcwd(), args.data_dir, 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    #yay dataframes, we can select rows and columns by their names\n",
    "    #we'll store the camera images as our input data\n",
    "    X = data_df[['center', 'left', 'right']].values\n",
    "    #and our steering commands as our output data\n",
    "    y = data_df['steering'].values\n",
    "\n",
    "    #now we can split the data into a training (80), testing(20), and validation set\n",
    "    #thanks scikit learn\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args.test_size, random_state=0)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5))\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = CarDataset(X_train, y_train, args.data_dir, True, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 ,.,.) = \n",
      " -0.9987 -0.9989 -0.9989  ...  -0.9970 -0.9964 -0.9967\n",
      " -0.9990 -0.9987 -0.9993  ...  -0.9968 -0.9962 -0.9969\n",
      " -0.9991 -0.9989 -0.9993  ...  -0.9966 -0.9957 -0.9962\n",
      "           ...             ⋱             ...          \n",
      " -0.9965 -0.9962 -0.9955  ...  -0.9968 -0.9956 -0.9948\n",
      " -0.9958 -0.9966 -0.9959  ...  -0.9967 -0.9965 -0.9970\n",
      " -0.9966 -0.9971 -0.9966  ...  -0.9966 -0.9971 -0.9962\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.9960 -0.9960 -0.9960  ...  -0.9957 -0.9957 -0.9957\n",
      " -0.9960 -0.9960 -0.9960  ...  -0.9957 -0.9957 -0.9957\n",
      " -0.9960 -0.9960 -0.9960  ...  -0.9957 -0.9957 -0.9957\n",
      "           ...             ⋱             ...          \n",
      " -0.9961 -0.9961 -0.9961  ...  -0.9959 -0.9959 -0.9959\n",
      " -0.9961 -0.9961 -0.9961  ...  -0.9960 -0.9959 -0.9959\n",
      " -0.9961 -0.9961 -0.9961  ...  -0.9960 -0.9960 -0.9960\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.9968 -0.9968 -0.9967  ...  -0.9970 -0.9971 -0.9971\n",
      " -0.9968 -0.9968 -0.9967  ...  -0.9970 -0.9971 -0.9972\n",
      " -0.9968 -0.9968 -0.9966  ...  -0.9970 -0.9971 -0.9972\n",
      "           ...             ⋱             ...          \n",
      " -0.9962 -0.9962 -0.9962  ...  -0.9967 -0.9967 -0.9967\n",
      " -0.9962 -0.9962 -0.9962  ...  -0.9966 -0.9966 -0.9967\n",
      " -0.9962 -0.9962 -0.9962  ...  -0.9964 -0.9966 -0.9967\n",
      "[torch.FloatTensor of size 3x66x200]\n",
      "\n",
      "-0.27358530000000003\n"
     ]
    }
   ],
   "source": [
    "test_image = 0\n",
    "for data, steer in train_loader:\n",
    "    print(data[0])\n",
    "    print(steer[0])\n",
    "    test_image = data[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = batch_generator(args.data_dir, X_train, y_train, args.batch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, tar = gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 66, 200, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center, left, right = X_train[1]\n",
    "steering_angle = y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, steering_angle = augument(args.data_dir, center, left, right, steering_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 320, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 200, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = transforms.ToTensor()(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### NVIDIA model used\n",
    "    Image normalization to avoid saturation and make gradients work better.\n",
    "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Drop out (0.5)\n",
    "    Fully connected: neurons: 100, activation: ELU\n",
    "    Fully connected: neurons: 50, activation: ELU\n",
    "    Fully connected: neurons: 10, activation: ELU\n",
    "    Fully connected: neurons: 1 (output)\n",
    "    \n",
    "    the convolution layers are meant to handle feature engineering\n",
    "    the fully connected layer for predicting the steering angle.\n",
    "    dropout avoids overfitting\n",
    "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, net, dataloader, optimizer, criterion, use_cuda):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets.float())\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        print('Loss: %.3f '\n",
    "            % (train_loss/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CarModel()\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate, weight_decay=5e-4)\n",
    "\n",
    "if args.cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Loss: 0.051 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.057 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 1\n",
      "Loss: 0.062 \n",
      "Loss: 0.068 \n",
      "Loss: 0.064 \n",
      "Loss: 0.061 \n",
      "Loss: 0.058 \n",
      "Loss: 0.060 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 2\n",
      "Loss: 0.056 \n",
      "Loss: 0.046 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 3\n",
      "Loss: 0.042 \n",
      "Loss: 0.043 \n",
      "Loss: 0.044 \n",
      "Loss: 0.044 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 4\n",
      "Loss: 0.045 \n",
      "Loss: 0.057 \n",
      "Loss: 0.054 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 5\n",
      "Loss: 0.063 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 6\n",
      "Loss: 0.049 \n",
      "Loss: 0.043 \n",
      "Loss: 0.045 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 7\n",
      "Loss: 0.048 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 8\n",
      "Loss: 0.043 \n",
      "Loss: 0.046 \n",
      "Loss: 0.049 \n",
      "Loss: 0.045 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 9\n",
      "Loss: 0.044 \n",
      "Loss: 0.049 \n",
      "Loss: 0.054 \n",
      "Loss: 0.049 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 10\n",
      "Loss: 0.040 \n",
      "Loss: 0.042 \n",
      "Loss: 0.053 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 11\n",
      "Loss: 0.094 \n",
      "Loss: 0.068 \n",
      "Loss: 0.068 \n",
      "Loss: 0.064 \n",
      "Loss: 0.063 \n",
      "Loss: 0.059 \n",
      "Loss: 0.057 \n",
      "Loss: 0.059 \n",
      "Loss: 0.058 \n",
      "Loss: 0.057 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 12\n",
      "Loss: 0.047 \n",
      "Loss: 0.057 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 13\n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.045 \n",
      "Loss: 0.052 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 14\n",
      "Loss: 0.038 \n",
      "Loss: 0.045 \n",
      "Loss: 0.044 \n",
      "Loss: 0.046 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 15\n",
      "Loss: 0.049 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 16\n",
      "Loss: 0.051 \n",
      "Loss: 0.058 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "\n",
      "Epoch: 17\n",
      "Loss: 0.046 \n",
      "Loss: 0.043 \n",
      "Loss: 0.054 \n",
      "Loss: 0.058 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 18\n",
      "Loss: 0.046 \n",
      "Loss: 0.042 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 19\n",
      "Loss: 0.046 \n",
      "Loss: 0.044 \n",
      "Loss: 0.044 \n",
      "Loss: 0.050 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 20\n",
      "Loss: 0.058 \n",
      "Loss: 0.060 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 21\n",
      "Loss: 0.052 \n",
      "Loss: 0.065 \n",
      "Loss: 0.060 \n",
      "Loss: 0.058 \n",
      "Loss: 0.060 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 22\n",
      "Loss: 0.041 \n",
      "Loss: 0.041 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 23\n",
      "Loss: 0.037 \n",
      "Loss: 0.036 \n",
      "Loss: 0.044 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 24\n",
      "Loss: 0.069 \n",
      "Loss: 0.058 \n",
      "Loss: 0.054 \n",
      "Loss: 0.059 \n",
      "Loss: 0.058 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 25\n",
      "Loss: 0.058 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 26\n",
      "Loss: 0.037 \n",
      "Loss: 0.044 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 27\n",
      "Loss: 0.064 \n",
      "Loss: 0.058 \n",
      "Loss: 0.057 \n",
      "Loss: 0.051 \n",
      "Loss: 0.048 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 28\n",
      "Loss: 0.032 \n",
      "Loss: 0.046 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 29\n",
      "Loss: 0.059 \n",
      "Loss: 0.048 \n",
      "Loss: 0.044 \n",
      "Loss: 0.046 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 30\n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.057 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 31\n",
      "Loss: 0.043 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 32\n",
      "Loss: 0.087 \n",
      "Loss: 0.064 \n",
      "Loss: 0.058 \n",
      "Loss: 0.058 \n",
      "Loss: 0.059 \n",
      "Loss: 0.057 \n",
      "Loss: 0.059 \n",
      "Loss: 0.059 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "\n",
      "Epoch: 33\n",
      "Loss: 0.030 \n",
      "Loss: 0.044 \n",
      "Loss: 0.044 \n",
      "Loss: 0.047 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 34\n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 35\n",
      "Loss: 0.052 \n",
      "Loss: 0.062 \n",
      "Loss: 0.060 \n",
      "Loss: 0.059 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 36\n",
      "Loss: 0.034 \n",
      "Loss: 0.042 \n",
      "Loss: 0.042 \n",
      "Loss: 0.043 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.053 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 37\n",
      "Loss: 0.061 \n",
      "Loss: 0.059 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 38\n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.054 \n",
      "Loss: 0.048 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 39\n",
      "Loss: 0.045 \n",
      "Loss: 0.043 \n",
      "Loss: 0.045 \n",
      "Loss: 0.044 \n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 40\n",
      "Loss: 0.042 \n",
      "Loss: 0.051 \n",
      "Loss: 0.047 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 41\n",
      "Loss: 0.042 \n",
      "Loss: 0.052 \n",
      "Loss: 0.058 \n",
      "Loss: 0.056 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.052 \n",
      "Loss: 0.057 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 42\n",
      "Loss: 0.066 \n",
      "Loss: 0.063 \n",
      "Loss: 0.059 \n",
      "Loss: 0.059 \n",
      "Loss: 0.059 \n",
      "Loss: 0.058 \n",
      "Loss: 0.055 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 43\n",
      "Loss: 0.060 \n",
      "Loss: 0.064 \n",
      "Loss: 0.058 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 44\n",
      "Loss: 0.051 \n",
      "Loss: 0.058 \n",
      "Loss: 0.058 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 45\n",
      "Loss: 0.045 \n",
      "Loss: 0.040 \n",
      "Loss: 0.046 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 46\n",
      "Loss: 0.047 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.048 \n",
      "Loss: 0.046 \n",
      "Loss: 0.044 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 47\n",
      "Loss: 0.045 \n",
      "Loss: 0.038 \n",
      "Loss: 0.046 \n",
      "Loss: 0.044 \n",
      "Loss: 0.046 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 48\n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 49\n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 50\n",
      "Loss: 0.055 \n",
      "Loss: 0.052 \n",
      "Loss: 0.047 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 51\n",
      "Loss: 0.041 \n",
      "Loss: 0.045 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 52\n",
      "Loss: 0.068 \n",
      "Loss: 0.062 \n",
      "Loss: 0.054 \n",
      "Loss: 0.056 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 53\n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.046 \n",
      "Loss: 0.042 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.047 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 54\n",
      "Loss: 0.061 \n",
      "Loss: 0.053 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 55\n",
      "Loss: 0.063 \n",
      "Loss: 0.064 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.047 \n",
      "Loss: 0.050 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 56\n",
      "Loss: 0.059 \n",
      "Loss: 0.056 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 57\n",
      "Loss: 0.072 \n",
      "Loss: 0.061 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 58\n",
      "Loss: 0.054 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.044 \n",
      "Loss: 0.048 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.055 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 59\n",
      "Loss: 0.041 \n",
      "Loss: 0.042 \n",
      "Loss: 0.043 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 60\n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.043 \n",
      "Loss: 0.043 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 61\n",
      "Loss: 0.055 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.059 \n",
      "Loss: 0.058 \n",
      "Loss: 0.057 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "\n",
      "Epoch: 62\n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.050 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 63\n",
      "Loss: 0.046 \n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.045 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 64\n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.047 \n",
      "Loss: 0.043 \n",
      "Loss: 0.044 \n",
      "Loss: 0.044 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 65\n",
      "Loss: 0.035 \n",
      "Loss: 0.038 \n",
      "Loss: 0.038 \n",
      "Loss: 0.038 \n",
      "Loss: 0.038 \n",
      "Loss: 0.043 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 66\n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.055 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 67\n",
      "Loss: 0.053 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 68\n",
      "Loss: 0.033 \n",
      "Loss: 0.042 \n",
      "Loss: 0.054 \n",
      "Loss: 0.059 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 69\n",
      "Loss: 0.072 \n",
      "Loss: 0.061 \n",
      "Loss: 0.058 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "\n",
      "Epoch: 70\n",
      "Loss: 0.044 \n",
      "Loss: 0.045 \n",
      "Loss: 0.058 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 71\n",
      "Loss: 0.058 \n",
      "Loss: 0.053 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.046 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 72\n",
      "Loss: 0.033 \n",
      "Loss: 0.036 \n",
      "Loss: 0.038 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 73\n",
      "Loss: 0.063 \n",
      "Loss: 0.060 \n",
      "Loss: 0.060 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.057 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 74\n",
      "Loss: 0.058 \n",
      "Loss: 0.062 \n",
      "Loss: 0.054 \n",
      "Loss: 0.051 \n",
      "Loss: 0.048 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "\n",
      "Epoch: 75\n",
      "Loss: 0.061 \n",
      "Loss: 0.049 \n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 76\n",
      "Loss: 0.027 \n",
      "Loss: 0.031 \n",
      "Loss: 0.041 \n",
      "Loss: 0.044 \n",
      "Loss: 0.045 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 77\n",
      "Loss: 0.059 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.057 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 78\n",
      "Loss: 0.037 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.045 \n",
      "Loss: 0.048 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 79\n",
      "Loss: 0.037 \n",
      "Loss: 0.037 \n",
      "Loss: 0.043 \n",
      "Loss: 0.046 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 80\n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 81\n",
      "Loss: 0.040 \n",
      "Loss: 0.047 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 82\n",
      "Loss: 0.043 \n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.054 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 83\n",
      "Loss: 0.040 \n",
      "Loss: 0.039 \n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.046 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.055 \n",
      "\n",
      "Epoch: 84\n",
      "Loss: 0.050 \n",
      "Loss: 0.048 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.049 \n",
      "Loss: 0.054 \n",
      "Loss: 0.046 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 86\n",
      "Loss: 0.054 \n",
      "Loss: 0.057 \n",
      "Loss: 0.057 \n",
      "Loss: 0.055 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 87\n",
      "Loss: 0.045 \n",
      "Loss: 0.049 \n",
      "Loss: 0.047 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "\n",
      "Epoch: 88\n",
      "Loss: 0.038 \n",
      "Loss: 0.040 \n",
      "Loss: 0.040 \n",
      "Loss: 0.046 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.046 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 89\n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.050 \n",
      "Loss: 0.048 \n",
      "Loss: 0.053 \n",
      "Loss: 0.056 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 90\n",
      "Loss: 0.056 \n",
      "Loss: 0.043 \n",
      "Loss: 0.044 \n",
      "Loss: 0.045 \n",
      "Loss: 0.047 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 91\n",
      "Loss: 0.046 \n",
      "Loss: 0.048 \n",
      "Loss: 0.050 \n",
      "Loss: 0.056 \n",
      "Loss: 0.061 \n",
      "Loss: 0.058 \n",
      "Loss: 0.056 \n",
      "Loss: 0.056 \n",
      "Loss: 0.058 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.054 \n",
      "\n",
      "Epoch: 92\n",
      "Loss: 0.042 \n",
      "Loss: 0.039 \n",
      "Loss: 0.044 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "\n",
      "Epoch: 93\n",
      "Loss: 0.037 \n",
      "Loss: 0.044 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 94\n",
      "Loss: 0.073 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.051 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 95\n",
      "Loss: 0.036 \n",
      "Loss: 0.044 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.053 \n",
      "Loss: 0.054 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 96\n",
      "Loss: 0.061 \n",
      "Loss: 0.055 \n",
      "Loss: 0.055 \n",
      "Loss: 0.059 \n",
      "Loss: 0.056 \n",
      "Loss: 0.059 \n",
      "Loss: 0.058 \n",
      "Loss: 0.057 \n",
      "Loss: 0.056 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.054 \n",
      "Loss: 0.053 \n",
      "\n",
      "Epoch: 97\n",
      "Loss: 0.063 \n",
      "Loss: 0.053 \n",
      "Loss: 0.052 \n",
      "Loss: 0.049 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.053 \n",
      "Loss: 0.050 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 98\n",
      "Loss: 0.040 \n",
      "Loss: 0.051 \n",
      "Loss: 0.052 \n",
      "Loss: 0.051 \n",
      "Loss: 0.050 \n",
      "Loss: 0.052 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 99\n",
      "Loss: 0.037 \n",
      "Loss: 0.037 \n",
      "Loss: 0.046 \n",
      "Loss: 0.049 \n",
      "Loss: 0.046 \n",
      "Loss: 0.046 \n",
      "Loss: 0.045 \n",
      "Loss: 0.046 \n",
      "Loss: 0.047 \n",
      "Loss: 0.049 \n",
      "Loss: 0.049 \n",
      "Loss: 0.048 \n",
      "Loss: 0.049 \n",
      "Loss: 0.050 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,100):\n",
    "    #optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\t\n",
    "    train(epoch, net, train_loader, optimizer, criterion, args.cuda)\n",
    "    #test(epoch, net, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "        'net': net.module if args.cuda else net,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pllab/miniconda2/envs/car-behavioral-cloning/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type CarModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(state, './model.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1000\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1000\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-d7365389e1d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/car-behavioral-cloning/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?"
     ]
    }
   ],
   "source": [
    "x.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
