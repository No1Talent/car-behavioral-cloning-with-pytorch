{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPifkfWOMZVb"
      },
      "source": [
        "# Experiment:\n",
        "\n",
        "Explore the dataset and build a model that can accept the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "tMeJHbXzMZVe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import argparse\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "Pk0QTF3QMZVg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "#from torchnet.meter import AverageValueMeter\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/')\n",
        "%pwd"
      ],
      "metadata": {
        "id": "CeW-RlwbeuGy",
        "outputId": "89bd2612-85dc-4fb6-8a76-07fabb73488a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "from model import *"
      ],
      "metadata": {
        "id": "gQwCyOhgfYzi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "MwFq454UMZVh"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "\n",
        "# Default parameters\n",
        "default_params = {\n",
        "    'data_dir': './data/',\n",
        "    'nb_epoch': 50,\n",
        "    'test_size': 0.1,\n",
        "    'learning_rate': 0.0001,\n",
        "    'samples_per_epoch': 64,\n",
        "    'batch_size': 36,\n",
        "    'cuda': True,\n",
        "    'seed': 7\n",
        "}\n",
        "\n",
        "# Parse command-line arguments\n",
        "args = argparse.Namespace(**default_params)\n",
        "\n",
        "# Adjust CUDA setting based on availability\n",
        "args.cuda = args.cuda and torch.cuda.is_available()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "OwFC8WrkMZVi"
      },
      "outputs": [],
      "source": [
        "def load_data(args):\n",
        "    \"\"\"\n",
        "    Load training data and split it into training and validation set\n",
        "    \"\"\"\n",
        "    #reads CSV file into a single dataframe variable\n",
        "    data_df = pd.read_csv(os.path.join(os.getcwd(), args.data_dir, 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
        "\n",
        "    #yay dataframes, we can select rows and columns by their names\n",
        "    #we'll store the camera images as our input data\n",
        "    X = data_df[['center', 'left', 'right']].values\n",
        "    #and our steering commands as our output data\n",
        "    y = data_df['steering'].values\n",
        "\n",
        "    #now we can split the data into a training (80), testing(20), and validation set\n",
        "    #thanks scikit learn\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args.test_size, random_state=0, shuffle=True)\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "fKYFysXuMZVi"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = load_data(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "XHyHukNsMZVj"
      },
      "outputs": [],
      "source": [
        "transformations = transforms.Compose([transforms.Lambda(lambda x: x/127.5 - 1)\n",
        "                                     ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "w8eu4vRMjt-w",
        "outputId": "b04f1459-a099-440d-909f-9aa16da0e2e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['IMG/center_2016_12_01_13_37_51_293.jpg',\n",
              "        ' IMG/left_2016_12_01_13_37_51_293.jpg',\n",
              "        ' IMG/right_2016_12_01_13_37_51_293.jpg'],\n",
              "       ['IMG/center_2016_12_01_13_37_35_908.jpg',\n",
              "        ' IMG/left_2016_12_01_13_37_35_908.jpg',\n",
              "        ' IMG/right_2016_12_01_13_37_35_908.jpg'],\n",
              "       ['IMG/center_2016_12_01_13_37_34_189.jpg',\n",
              "        ' IMG/left_2016_12_01_13_37_34_189.jpg',\n",
              "        ' IMG/right_2016_12_01_13_37_34_189.jpg'],\n",
              "       ...,\n",
              "       ['IMG/center_2016_12_01_13_35_25_756.jpg',\n",
              "        ' IMG/left_2016_12_01_13_35_25_756.jpg',\n",
              "        ' IMG/right_2016_12_01_13_35_25_756.jpg'],\n",
              "       ['IMG/center_2016_12_01_13_37_02_415.jpg',\n",
              "        ' IMG/left_2016_12_01_13_37_02_415.jpg',\n",
              "        ' IMG/right_2016_12_01_13_37_02_415.jpg'],\n",
              "       ['IMG/center_2016_12_01_13_37_15_051.jpg',\n",
              "        ' IMG/left_2016_12_01_13_37_15_051.jpg',\n",
              "        ' IMG/right_2016_12_01_13_37_15_051.jpg']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "lSynvkGEMZVj"
      },
      "outputs": [],
      "source": [
        "#train_set = CarDataset(X_train, y_train, args.data_dir, False,transformations)\n",
        "train_set = CarDataset3Img(X_train, y_train, args.data_dir,transformations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "dSv7e7jxMZVj"
      },
      "outputs": [],
      "source": [
        "valid_set = CarDataset(X_valid, y_valid, args.data_dir, False, transformations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "Grhoq9zxMZVk",
        "outputId": "3310f169-7d01-45c2-c73c-805c57b6b261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "njPuHNUOMZVk"
      },
      "outputs": [],
      "source": [
        "valid_loader = DataLoader(valid_set, batch_size=args.batch_size, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d0KWq7CMZVk"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy_KwnkXMZVk"
      },
      "source": [
        " ### NVIDIA Model\n",
        "    Image normalization to avoid saturation and make gradients work better.\n",
        "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Drop out (0.5)\n",
        "    Fully connected: neurons: 100, activation: ELU\n",
        "    Fully connected: neurons: 50, activation: ELU\n",
        "    Fully connected: neurons: 10, activation: ELU\n",
        "    Fully connected: neurons: 1 (output)\n",
        "    \n",
        "    the convolution layers are meant to handle feature engineering\n",
        "    the fully connected layer for predicting the steering angle.\n",
        "    dropout avoids overfitting\n",
        "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem.\n",
        "    \n",
        "### Simple Model\n",
        "\n",
        "```\n",
        "  (module): CarSimpleModel (\n",
        "    (conv_layers): Sequential (\n",
        "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
        "      (1): ELU (alpha=1.0)\n",
        "      (2): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
        "      (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
        "      (4): Dropout (p = 0.25)\n",
        "    )\n",
        "    (linear_layers): Sequential (\n",
        "      (0): Linear (3648 -> 50)\n",
        "      (1): ELU (alpha=1.0)\n",
        "      (2): Linear (50 -> 10)\n",
        "      (3): Linear (10 -> 1)\n",
        "    )\n",
        "  )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE1lq6-zMZVn"
      },
      "source": [
        "# Define Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "iw2pkHsMMZVn"
      },
      "outputs": [],
      "source": [
        "def toVariable(data, use_cuda):\n",
        "    input, target = data\n",
        "    input, target = Variable(input.float()), Variable(target.float())\n",
        "    if use_cuda:\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "\n",
        "    return input, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "gmfjelPaMZVn"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch, net, dataloader, optimizer, criterion, use_cuda):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (centers, lefts, rights) in enumerate(dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        centers, lefts, rights = toVariable(centers, use_cuda), \\\n",
        "                                 toVariable(lefts, use_cuda), \\\n",
        "                                 toVariable(rights, use_cuda)\n",
        "        datas = [lefts, rights, centers]\n",
        "        for data in datas:\n",
        "            imgs, targets = data\n",
        "            outputs = net(imgs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.data[0]\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Loss: %.3f '\n",
        "                % (train_loss/((batch_idx+1)*3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVG6xFnKMZVo"
      },
      "source": [
        "## Define Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "GCMG8o-TMZVo"
      },
      "outputs": [],
      "source": [
        "def valid(epoch, net, validloader, criterion, use_cuda):\n",
        "    global best_loss\n",
        "    net.eval()\n",
        "    valid_loss = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(validloader):\n",
        "        inputs, targets = Variable(inputs.float()), Variable(targets.float())\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        valid_loss += loss.data[0]\n",
        "\n",
        "        avg_valid_loss = valid_loss/(batch_idx+1)\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Valid Loss: %.3f '\n",
        "                % (valid_loss/(batch_idx+1)))\n",
        "        if avg_valid_loss <= best_loss:\n",
        "            best_loss = avg_valid_loss\n",
        "            print('Best epoch: ' + str(epoch))\n",
        "            state = {\n",
        "                'net': net.module if args.cuda else net,\n",
        "            }\n",
        "            torch.save(state, './model3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "JuKFWBOBMZVo",
        "outputId": "ee166824-6c5b-45ec-dad6-939bad1a7edf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/model.py:153: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  init.normal(m.weight, mean=0, std=0.02)\n"
          ]
        }
      ],
      "source": [
        "net = CarSimpleModel()\n",
        "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate)\n",
        "\n",
        "if args.cuda:\n",
        "    net.cuda()\n",
        "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "juui9u0FMZVo"
      },
      "outputs": [],
      "source": [
        "best_loss = 0.999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": false,
        "id": "IKZB4sbzMZVo",
        "outputId": "811d9738-9eb5-4c03-fe43-2fe857098488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5980b36fa68c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-4a1d37389248>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, net, dataloader, optimizer, criterion, use_cuda)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/utils.py\", line 187, in __getitem__\n    image_left, steering_angle_left = augument_img(load_image(self.data_dir, left), steering_angle + 0.1)\n  File \"/content/utils.py\", line 14, in load_image\n    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n  File \"/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\", line 1563, in imread\n    with img_open(fname) as image:\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: './data/IMG/left_2016_12_01_13_33_04_486.jpg'\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0,15):\n",
        "    #optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    train(epoch, net, train_loader, optimizer, criterion, args.cuda)\n",
        "    valid(epoch, net, valid_loader, criterion, args.cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro0nWdNjMZVo"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_UZLXEoaMZVo"
      },
      "outputs": [],
      "source": [
        "state = {\n",
        "        'net': net.module if args.cuda else net,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d_qHW8q3MZVo"
      },
      "outputs": [],
      "source": [
        "torch.save(state, './model4.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jkrySdedMZVo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}