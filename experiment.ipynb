{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment:\n",
    "\n",
    "Explore the dataset and build a model that can accept the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "#from torchnet.meter import AverageValueMeter\n",
    "import torch.backends.cudnn as cudnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_dir': './selfdrivingcar-data/normalRace/',\n",
    "    'nb_epoch': 50,\n",
    "    'test_size': 64,\n",
    "    'learning_rate': 0.0001,\n",
    "    'samples_per_epoch': 64,\n",
    "    'batch_size': 40,\n",
    "    'cuda': True,\n",
    "    'seed': 7\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \"\"\"\n",
    "    #reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(os.getcwd(), args.data_dir, 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    #yay dataframes, we can select rows and columns by their names\n",
    "    #we'll store the camera images as our input data\n",
    "    X = data_df[['center', 'left', 'right']].values\n",
    "    #and our steering commands as our output data\n",
    "    y = data_df['steering'].values\n",
    "\n",
    "    #now we can split the data into a training (80), testing(20), and validation set\n",
    "    #thanks scikit learn\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args.test_size, random_state=0)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5))\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = CarDataset(X_train, y_train, args.data_dir, True, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_image = 0\n",
    "for data, steer in train_loader:\n",
    "    print(data[0])\n",
    "    print(steer[0])\n",
    "    test_image = data[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### NVIDIA model used\n",
    "    Image normalization to avoid saturation and make gradients work better.\n",
    "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Drop out (0.5)\n",
    "    Fully connected: neurons: 100, activation: ELU\n",
    "    Fully connected: neurons: 50, activation: ELU\n",
    "    Fully connected: neurons: 10, activation: ELU\n",
    "    Fully connected: neurons: 1 (output)\n",
    "    \n",
    "    the convolution layers are meant to handle feature engineering\n",
    "    the fully connected layer for predicting the steering angle.\n",
    "    dropout avoids overfitting\n",
    "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, net, dataloader, optimizer, criterion, use_cuda):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets.float())\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Loss: %.3f '\n",
    "                % (train_loss/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = CarModel()\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate)\n",
    "\n",
    "if args.cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Loss: 0.078 \n",
      "\n",
      "Epoch: 1\n",
      "Loss: 0.038 \n",
      "\n",
      "Epoch: 2\n",
      "Loss: 0.031 \n",
      "\n",
      "Epoch: 3\n",
      "Loss: 0.046 \n",
      "\n",
      "Epoch: 4\n",
      "Loss: 0.030 \n",
      "\n",
      "Epoch: 5\n",
      "Loss: 0.035 \n",
      "\n",
      "Epoch: 6\n",
      "Loss: 0.041 \n",
      "\n",
      "Epoch: 7\n",
      "Loss: 0.049 \n",
      "\n",
      "Epoch: 8\n",
      "Loss: 0.055 \n",
      "\n",
      "Epoch: 9\n",
      "Loss: 0.023 \n",
      "\n",
      "Epoch: 10\n",
      "Loss: 0.034 \n",
      "\n",
      "Epoch: 11\n",
      "Loss: 0.027 \n",
      "\n",
      "Epoch: 12\n",
      "Loss: 0.045 \n",
      "\n",
      "Epoch: 13\n",
      "Loss: 0.038 \n",
      "\n",
      "Epoch: 14\n",
      "Loss: 0.043 \n",
      "\n",
      "Epoch: 15\n",
      "Loss: 0.036 \n",
      "\n",
      "Epoch: 16\n",
      "Loss: 0.038 \n",
      "\n",
      "Epoch: 17\n",
      "Loss: 0.035 \n",
      "\n",
      "Epoch: 18\n",
      "Loss: 0.039 \n",
      "\n",
      "Epoch: 19\n",
      "Loss: 0.022 \n",
      "\n",
      "Epoch: 20\n",
      "Loss: 0.052 \n",
      "\n",
      "Epoch: 21\n",
      "Loss: 0.058 \n",
      "\n",
      "Epoch: 22\n",
      "Loss: 0.036 \n",
      "\n",
      "Epoch: 23\n",
      "Loss: 0.078 \n",
      "\n",
      "Epoch: 24\n",
      "Loss: 0.027 \n",
      "\n",
      "Epoch: 25\n",
      "Loss: 0.034 \n",
      "\n",
      "Epoch: 26\n",
      "Loss: 0.025 \n",
      "\n",
      "Epoch: 27\n",
      "Loss: 0.039 \n",
      "\n",
      "Epoch: 28\n",
      "Loss: 0.028 \n",
      "\n",
      "Epoch: 29\n",
      "Loss: 0.026 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,30):\n",
    "    #optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\t\n",
    "    train(epoch, net, train_loader, optimizer, criterion, args.cuda)\n",
    "    #test(epoch, net, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = {\n",
    "        'net': net.module if args.cuda else net,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(state, './model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "data_df = pd.read_csv(os.path.join(os.getcwd(), args.data_dir, 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
